
import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";

let chatSession: Chat | null = null;
let aiClient: GoogleGenAI | null = null;
let lastError: string | null = null;

// Funci√≥n para obtener el cliente, asegurando que se crea con la clave
const getAiClient = (): GoogleGenAI | null => {
    if (aiClient) return aiClient;
    
    // Intento 1: process.env (Standard/Vercel)
    let apiKey = process.env.API_KEY;

    // Intento 2: import.meta.env (Vite nativo) - Fallback
    if (!apiKey || apiKey === 'undefined' || apiKey === '') {
        // @ts-ignore
        if (import.meta.env && import.meta.env.VITE_API_KEY) {
            // @ts-ignore
            apiKey = import.meta.env.VITE_API_KEY;
        }
    }
    
    if (!apiKey || apiKey === 'undefined' || apiKey === '') {
        console.warn("‚ö†Ô∏è API Key de Google GenAI no detectada.");
        lastError = "Falta la API Key en la configuraci√≥n.";
        return null;
    }
    
    try {
        aiClient = new GoogleGenAI({ apiKey: apiKey });
        console.log("üü¢ Cliente IA creado.");
        return aiClient;
    } catch (e: any) {
        console.error("Error fatal inicializando cliente AI:", e);
        lastError = e.message || "Error al inicializar cliente.";
        return null;
    }
};

// Funci√≥n para iniciar o reiniciar el chat con un contexto espec√≠fico
export async function startNewChat(contextData: string = ""): Promise<boolean> {
    aiClient = null; 
    const ai = getAiClient();
    
    if (!ai) {
        chatSession = null;
        return false;
    }

    const systemInstruction = `
Eres Gemini, un asistente en la app "Consulta de Tarifas".
TU COMPORTAMIENTO:
1. Responde SIEMPRE EN ESPA√ëOL.
2. S√© profesional y conciso.
3. Usa los siguientes datos para responder si es pertinente:
${contextData ? contextData.substring(0, 40000) : "Sin datos visualizados."}
    `;

    try {
        // INTENTO 1: Modelo Principal (Gemini 3)
        chatSession = ai.chats.create({
            model: 'gemini-3-flash-preview',
            config: { systemInstruction, temperature: 0.7 },
        });
        console.log("‚úÖ Chat Gemini 3 iniciado.");
        return true;
    } catch (error) {
        console.warn("‚ö†Ô∏è Fallo Gemini 3, intentando modelo de respaldo...", error);
        try {
            // INTENTO 2: Modelo de Respaldo (Gemini 2.5) - M√°s estable si el 3 falla
            chatSession = ai.chats.create({
                model: 'gemini-2.5-flash',
                config: { systemInstruction, temperature: 0.7 },
            });
            console.log("‚úÖ Chat Gemini 2.5 iniciado (Fallback).");
            return true;
        } catch (err2: any) {
            console.error("‚ùå Error fatal creando sesi√≥n de chat:", err2);
            chatSession = null;
            lastError = err2.message || "Error al crear sesi√≥n.";
            return false;
        }
    }
}

export async function getBotResponse(message: string): Promise<string> {
  try {
    // Si no hay sesi√≥n, intentar iniciar una nueva al vuelo
    if (!chatSession) {
        console.log("üîÑ Intentando reconexi√≥n autom√°tica...");
        const success = await startNewChat();
        if (!success) {
            return `Error de conexi√≥n: ${lastError || "Verifica tu API Key."}`;
        }
    }

    if (!chatSession) {
        return "Error cr√≠tico: No se pudo establecer comunicaci√≥n con la IA.";
    }

    const result: GenerateContentResponse = await chatSession.sendMessage({ message: message });
    
    if (result && result.text) {
        return result.text;
    } else {
        return "No he recibido una respuesta v√°lida. Por favor, int√©ntalo de nuevo.";
    }

  } catch (error: any) {
    console.error("Error API Gemini:", error);
    chatSession = null; // Forzar reinicio para la pr√≥xima
    aiClient = null;

    if (error.message && (error.message.includes('API key') || error.message.includes('403'))) {
        return "Error de autenticaci√≥n: Tu API Key no es v√°lida o ha caducado.";
    }
    
    return "Ha ocurrido un error de conexi√≥n temporal. Por favor, pregunta de nuevo.";
  }
}
